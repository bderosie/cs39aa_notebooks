{"cells":[{"cell_type":"markdown","metadata":{},"source":["# CS 39AA Text Generation: Pre-trained GPT-2 Model\n","\n","Using a pre-trained transformer model, let's see what kind of text generation results we can get. We'll later see how this compares when we fine-tune this model using a corpus of our choice. To facilitate a comparison between the two we will use the same prompt for both. \n","\n","The hugginface documentation on how to do text generation with a pre-trained model can be found here:\n","* https://huggingface.co/transformers/v4.0.1/task_summary.html#text-generation\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import pandas as pd\n","from transformers import AutoModelWithLMHead, AutoTokenizer"]},{"cell_type":"markdown","metadata":{},"source":["The model we're choosing to use is the GPT-2 model, which can be found here:\n","* https://huggingface.co/gpt2-medium"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/Users/steve/opt/anaconda3/envs/torch13/lib/python3.9/site-packages/transformers/models/auto/modeling_auto.py:1132: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n","  warnings.warn(\n","NOTE: Redirects are currently not supported in Windows or MacOs.\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"78fa11a66fd34ae7bcee764c3dcac65d","version_major":2,"version_minor":0},"text/plain":["Downloading:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["MODEL_NAME = 'gpt2-medium'\n","\n","model = AutoModelWithLMHead.from_pretrained(MODEL_NAME)\n","tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["prompt = \"The old sailor hit\"\n","inputs = tokenizer.encode(prompt, add_special_tokens=False, return_tensors=\"pt\")"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"]}],"source":["prompt_length = len(tokenizer.decode(inputs[0], skip_special_tokens=True, clean_up_tokenization_spaces=True))\n","outputs = model.generate(inputs, max_length=20, do_sample=True, top_p=0.95, top_k=50, temperature=1.5, num_return_sequences=20)\n"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["The old sailor hit her and started the old woman against her, that this was no old woman and\n","The old sailor hit her in the face.\n","\n","\n","They're in bed\n","\n","\n","You're standing\n","The old sailor hit us right on the balls side in the bottom and when the boat swung his arm\n","The old sailor hit the water,\" said the president, according to one local paper of a scene at\n","The old sailor hit the rocks with a wet nose. \"Hey, just give him another chance,\"\n","The old sailor hit me with a bottle, like two of his crew did after he shot myself,\"\n","The old sailor hit his head when attempting to pull it from shore:\n","In contrast to being so\n","The old sailor hit me squarely there.\n","\n","The one I liked in a way. He was\n","The old sailor hit me like a ton of bricks and drove across half a square mile of it when\n","The old sailor hitched a ride for us. There's something comforting in a story.\n","\n","\n","The old sailor hit the deck and gave an explanation but with difficulty and at first too vague. He\n","The old sailor hit and clanked in the corner of my vision for seconds. As he came across\n","The old sailor hit a patch of ground between three houses to retrieve the bag of coins that he had\n","The old sailor hit you again and said something along those lines, when one could imagine the same things\n","The old sailor hit like we were hitting a barn... It could be called rock, paper, scissors\n","The old sailor hit me upside the head right with a crowbar and it was like thunder.\n","\n","The old sailor hit himself on top of one of the pillars and fell, screaming \"Killing the\n","The old sailor hit the snoozer, but it won't go for long, it didn't\n","The old sailor hit with a one-year suspended prison sentence for sexual misconduct for violating the terms of\n","The old sailor hit upon the idea of sending his brother and a sailor friend aboard the HMS St John\n"]}],"source":["for i in range(len(outputs)):\n","    generated = tokenizer.decode(outputs[i])\n","    print(generated)"]}],"metadata":{"kernelspec":{"display_name":"torch13","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13 (main, Aug 25 2022, 18:24:45) \n[Clang 12.0.0 ]"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"67f030e82dc83e46e375c9862143c2f050702bf26aeee9494179d0591d712143"}}},"nbformat":4,"nbformat_minor":2}

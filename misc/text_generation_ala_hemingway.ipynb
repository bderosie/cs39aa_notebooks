{"cells":[{"cell_type":"markdown","metadata":{},"source":["# CS 39AA Text Generation: Model Fine-tuned w/ Hemingway\n","\n","Let's now see what kind of results we can get if we take the same model but fine tune on what some say is Hemingway's best novel, 'The Sun Also Rises'. "]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["NOTE: Redirects are currently not supported in Windows or MacOs.\n"]}],"source":["import pandas as pd\n","import torch\n","from torch.utils.data import Dataset, random_split\n","from transformers import GPT2Tokenizer, TrainingArguments, Trainer, GPT2LMHeadModel"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["loading file vocab.json from cache at /Users/steve/.cache/huggingface/hub/models--gpt2-medium/snapshots/e852c9080bc759a01663acf5a828d95b261a9903/vocab.json\n","loading file merges.txt from cache at /Users/steve/.cache/huggingface/hub/models--gpt2-medium/snapshots/e852c9080bc759a01663acf5a828d95b261a9903/merges.txt\n","loading file added_tokens.json from cache at None\n","loading file special_tokens_map.json from cache at None\n","loading file tokenizer_config.json from cache at None\n","loading configuration file config.json from cache at /Users/steve/.cache/huggingface/hub/models--gpt2-medium/snapshots/e852c9080bc759a01663acf5a828d95b261a9903/config.json\n","Model config GPT2Config {\n","  \"_name_or_path\": \"gpt2-medium\",\n","  \"activation_function\": \"gelu_new\",\n","  \"architectures\": [\n","    \"GPT2LMHeadModel\"\n","  ],\n","  \"attn_pdrop\": 0.1,\n","  \"bos_token_id\": 50256,\n","  \"embd_pdrop\": 0.1,\n","  \"eos_token_id\": 50256,\n","  \"initializer_range\": 0.02,\n","  \"layer_norm_epsilon\": 1e-05,\n","  \"model_type\": \"gpt2\",\n","  \"n_ctx\": 1024,\n","  \"n_embd\": 1024,\n","  \"n_head\": 16,\n","  \"n_inner\": null,\n","  \"n_layer\": 24,\n","  \"n_positions\": 1024,\n","  \"n_special\": 0,\n","  \"predict_special_tokens\": true,\n","  \"reorder_and_upcast_attn\": false,\n","  \"resid_pdrop\": 0.1,\n","  \"scale_attn_by_inverse_layer_idx\": false,\n","  \"scale_attn_weights\": true,\n","  \"summary_activation\": null,\n","  \"summary_first_dropout\": 0.1,\n","  \"summary_proj_to_labels\": true,\n","  \"summary_type\": \"cls_index\",\n","  \"summary_use_proj\": true,\n","  \"task_specific_params\": {\n","    \"text-generation\": {\n","      \"do_sample\": true,\n","      \"max_length\": 50\n","    }\n","  },\n","  \"transformers_version\": \"4.24.0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 50257\n","}\n","\n","Adding <|startoftext|> to the vocabulary\n","Adding <|pad|> to the vocabulary\n","Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","loading configuration file config.json from cache at /Users/steve/.cache/huggingface/hub/models--gpt2-medium/snapshots/e852c9080bc759a01663acf5a828d95b261a9903/config.json\n","Model config GPT2Config {\n","  \"activation_function\": \"gelu_new\",\n","  \"architectures\": [\n","    \"GPT2LMHeadModel\"\n","  ],\n","  \"attn_pdrop\": 0.1,\n","  \"bos_token_id\": 50256,\n","  \"embd_pdrop\": 0.1,\n","  \"eos_token_id\": 50256,\n","  \"initializer_range\": 0.02,\n","  \"layer_norm_epsilon\": 1e-05,\n","  \"model_type\": \"gpt2\",\n","  \"n_ctx\": 1024,\n","  \"n_embd\": 1024,\n","  \"n_head\": 16,\n","  \"n_inner\": null,\n","  \"n_layer\": 24,\n","  \"n_positions\": 1024,\n","  \"n_special\": 0,\n","  \"predict_special_tokens\": true,\n","  \"reorder_and_upcast_attn\": false,\n","  \"resid_pdrop\": 0.1,\n","  \"scale_attn_by_inverse_layer_idx\": false,\n","  \"scale_attn_weights\": true,\n","  \"summary_activation\": null,\n","  \"summary_first_dropout\": 0.1,\n","  \"summary_proj_to_labels\": true,\n","  \"summary_type\": \"cls_index\",\n","  \"summary_use_proj\": true,\n","  \"task_specific_params\": {\n","    \"text-generation\": {\n","      \"do_sample\": true,\n","      \"max_length\": 50\n","    }\n","  },\n","  \"transformers_version\": \"4.24.0\",\n","  \"use_cache\": true,\n","  \"vocab_size\": 50257\n","}\n","\n","loading weights file pytorch_model.bin from cache at /Users/steve/.cache/huggingface/hub/models--gpt2-medium/snapshots/e852c9080bc759a01663acf5a828d95b261a9903/pytorch_model.bin\n","All model checkpoint weights were used when initializing GPT2LMHeadModel.\n","\n","All the weights of GPT2LMHeadModel were initialized from the model checkpoint at gpt2-medium.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use GPT2LMHeadModel for predictions without further training.\n"]},{"data":{"text/plain":["Embedding(50259, 1024)"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["MODEL_NAME = 'gpt2-medium'\n","\n","tokenizer = GPT2Tokenizer.from_pretrained(MODEL_NAME, bos_token='<|startoftext|>', eos_token='<|endoftext|>', pad_token='<|pad|>')\n","model = GPT2LMHeadModel.from_pretrained(MODEL_NAME)\n","model.resize_token_embeddings(len(tokenizer))"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"data":{"text/plain":["0    Robert Cohn was once middleweight boxing champ...\n","1    Do not think that I am very much impressed by ...\n","2    He cared nothing for boxing, in fact he dislik...\n","3    There was a certain inner comfort in knowing h...\n","4                    He was Spider Kellyâ€™s star pupil.\n","Name: sentence, dtype: object"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["sentences = pd.read_csv('/Users/steve/sunalsorises.csv')['sentence']\n","sentences.head()"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["max_length = max([len(tokenizer.encode(sentence)) for sentence in sentences])"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"data":{"text/plain":["224"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["max_length"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":["class HemingwayDataset(Dataset):\n","    def __init__(self, txt_list, tokenizer, max_length):\n","        self.input_ids = []\n","        self.attn_masks = []\n","        self.labels = []\n","        for txt in txt_list:\n","            encodings_dict = tokenizer('<|startoftext|>' + txt + '<|endoftext|>', truncation=True,\n","                                       max_length=max_length, padding=\"max_length\")\n","            self.input_ids.append(torch.tensor(encodings_dict['input_ids']))\n","            self.attn_masks.append(torch.tensor(encodings_dict['attention_mask']))\n","\n","    def __len__(self):\n","        return len(self.input_ids)\n","\n","    def __getitem__(self, idx):\n","        return self.input_ids[idx], self.attn_masks[idx]\n","\n"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[],"source":["dataset = HemingwayDataset(sentences, tokenizer, max_length=max_length)\n","train_size = int(0.9 * len(dataset))\n","train_dataset, val_dataset = random_split(dataset, [train_size, len(dataset) - train_size])"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"data":{"text/plain":["(tensor([50257,   447,   247,   447,   251,   564,   250,  1212,  8237,   318,\n","          1165,   922,   329, 27805,    12,  7109,  8040,    11,   616, 13674,\n","            13, 50256, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n","         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n","         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n","         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n","         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n","         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n","         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n","         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n","         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n","         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n","         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n","         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n","         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n","         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n","         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n","         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n","         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n","         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n","         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n","         50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258, 50258,\n","         50258, 50258, 50258, 50258]),\n"," tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","         0, 0, 0, 0, 0, 0, 0, 0]))"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["train_dataset[0]"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"data":{"text/plain":["4"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["import gc\n","gc.collect()"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["PyTorch: setting up devices\n"]}],"source":["training_args = TrainingArguments(output_dir='/Users/steve/models/hemingway_generation', num_train_epochs=1, logging_steps=100, save_steps=5000,\n","                                  per_device_train_batch_size=1, per_device_eval_batch_size=1,\n","                                  warmup_steps=10, weight_decay=0.05, logging_dir='/Users/steve/models/hemingway_generation/logs', report_to = 'none')"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/Users/steve/opt/anaconda3/envs/torch13/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","***** Running training *****\n","  Num examples = 6143\n","  Num Epochs = 1\n","  Instantaneous batch size per device = 1\n","  Total train batch size (w. parallel, distributed & accumulation) = 1\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 6143\n","  Number of trainable parameters = 354825216\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ed2f755aff55465b9ae537f510a6bf9a","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/6143 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["{'loss': 0.6824, 'learning_rate': 4.9266264470895154e-05, 'epoch': 0.02}\n","{'loss': 0.2265, 'learning_rate': 4.845100277188978e-05, 'epoch': 0.03}\n","{'loss': 0.201, 'learning_rate': 4.76357410728844e-05, 'epoch': 0.05}\n","{'loss': 0.1972, 'learning_rate': 4.6820479373879014e-05, 'epoch': 0.07}\n","{'loss': 0.21, 'learning_rate': 4.6005217674873634e-05, 'epoch': 0.08}\n","{'loss': 0.2374, 'learning_rate': 4.5189955975868254e-05, 'epoch': 0.1}\n","{'loss': 0.2055, 'learning_rate': 4.4374694276862874e-05, 'epoch': 0.11}\n","{'loss': 0.2246, 'learning_rate': 4.3559432577857494e-05, 'epoch': 0.13}\n","{'loss': 0.1911, 'learning_rate': 4.2744170878852114e-05, 'epoch': 0.15}\n","{'loss': 0.2071, 'learning_rate': 4.1928909179846734e-05, 'epoch': 0.16}\n","{'loss': 0.1874, 'learning_rate': 4.111364748084135e-05, 'epoch': 0.18}\n","{'loss': 0.1961, 'learning_rate': 4.0298385781835974e-05, 'epoch': 0.2}\n","{'loss': 0.1987, 'learning_rate': 3.9483124082830593e-05, 'epoch': 0.21}\n","{'loss': 0.2168, 'learning_rate': 3.8667862383825207e-05, 'epoch': 0.23}\n","{'loss': 0.1748, 'learning_rate': 3.7852600684819827e-05, 'epoch': 0.24}\n","{'loss': 0.2177, 'learning_rate': 3.7037338985814446e-05, 'epoch': 0.26}\n","{'loss': 0.2454, 'learning_rate': 3.6222077286809066e-05, 'epoch': 0.28}\n","{'loss': 0.2026, 'learning_rate': 3.5406815587803686e-05, 'epoch': 0.29}\n","{'loss': 0.2128, 'learning_rate': 3.4591553888798306e-05, 'epoch': 0.31}\n","{'loss': 0.2011, 'learning_rate': 3.3776292189792926e-05, 'epoch': 0.33}\n","{'loss': 0.2077, 'learning_rate': 3.296103049078754e-05, 'epoch': 0.34}\n","{'loss': 0.1869, 'learning_rate': 3.2145768791782166e-05, 'epoch': 0.36}\n","{'loss': 0.2339, 'learning_rate': 3.1330507092776786e-05, 'epoch': 0.37}\n","{'loss': 0.1935, 'learning_rate': 3.0515245393771403e-05, 'epoch': 0.39}\n","{'loss': 0.1936, 'learning_rate': 2.969998369476602e-05, 'epoch': 0.41}\n","{'loss': 0.1851, 'learning_rate': 2.888472199576064e-05, 'epoch': 0.42}\n","{'loss': 0.2135, 'learning_rate': 2.8069460296755262e-05, 'epoch': 0.44}\n","{'loss': 0.2007, 'learning_rate': 2.725419859774988e-05, 'epoch': 0.46}\n","{'loss': 0.2067, 'learning_rate': 2.64389368987445e-05, 'epoch': 0.47}\n","{'loss': 0.1952, 'learning_rate': 2.5623675199739115e-05, 'epoch': 0.49}\n","{'loss': 0.1804, 'learning_rate': 2.480841350073374e-05, 'epoch': 0.5}\n","{'loss': 0.2122, 'learning_rate': 2.3993151801728355e-05, 'epoch': 0.52}\n","{'loss': 0.2191, 'learning_rate': 2.3177890102722975e-05, 'epoch': 0.54}\n","{'loss': 0.2111, 'learning_rate': 2.2362628403717595e-05, 'epoch': 0.55}\n","{'loss': 0.1861, 'learning_rate': 2.154736670471221e-05, 'epoch': 0.57}\n","{'loss': 0.1767, 'learning_rate': 2.0732105005706835e-05, 'epoch': 0.59}\n","{'loss': 0.1777, 'learning_rate': 1.991684330670145e-05, 'epoch': 0.6}\n","{'loss': 0.2002, 'learning_rate': 1.910158160769607e-05, 'epoch': 0.62}\n","{'loss': 0.2047, 'learning_rate': 1.828631990869069e-05, 'epoch': 0.63}\n","{'loss': 0.1726, 'learning_rate': 1.7471058209685308e-05, 'epoch': 0.65}\n","{'loss': 0.2025, 'learning_rate': 1.665579651067993e-05, 'epoch': 0.67}\n","{'loss': 0.1869, 'learning_rate': 1.5840534811674548e-05, 'epoch': 0.68}\n","{'loss': 0.2391, 'learning_rate': 1.5025273112669166e-05, 'epoch': 0.7}\n","{'loss': 0.1684, 'learning_rate': 1.4210011413663788e-05, 'epoch': 0.72}\n","{'loss': 0.209, 'learning_rate': 1.3394749714658406e-05, 'epoch': 0.73}\n","{'loss': 0.1836, 'learning_rate': 1.2579488015653026e-05, 'epoch': 0.75}\n","{'loss': 0.1942, 'learning_rate': 1.1764226316647644e-05, 'epoch': 0.77}\n","{'loss': 0.2266, 'learning_rate': 1.0948964617642264e-05, 'epoch': 0.78}\n","{'loss': 0.1669, 'learning_rate': 1.0133702918636882e-05, 'epoch': 0.8}\n"]},{"name":"stderr","output_type":"stream","text":["Saving model checkpoint to /Users/steve/models/hemingway_generation/checkpoint-5000\n","Configuration saved in /Users/steve/models/hemingway_generation/checkpoint-5000/config.json\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.1837, 'learning_rate': 9.318441219631502e-06, 'epoch': 0.81}\n"]},{"name":"stderr","output_type":"stream","text":["Model weights saved in /Users/steve/models/hemingway_generation/checkpoint-5000/pytorch_model.bin\n"]},{"name":"stdout","output_type":"stream","text":["{'loss': 0.1973, 'learning_rate': 8.503179520626122e-06, 'epoch': 0.83}\n","{'loss': 0.1723, 'learning_rate': 7.68791782162074e-06, 'epoch': 0.85}\n","{'loss': 0.1748, 'learning_rate': 6.87265612261536e-06, 'epoch': 0.86}\n","{'loss': 0.1857, 'learning_rate': 6.057394423609979e-06, 'epoch': 0.88}\n","{'loss': 0.2087, 'learning_rate': 5.2421327246045984e-06, 'epoch': 0.9}\n","{'loss': 0.1846, 'learning_rate': 4.4268710255992175e-06, 'epoch': 0.91}\n","{'loss': 0.2186, 'learning_rate': 3.6116093265938366e-06, 'epoch': 0.93}\n","{'loss': 0.1871, 'learning_rate': 2.796347627588456e-06, 'epoch': 0.94}\n","{'loss': 0.178, 'learning_rate': 1.981085928583075e-06, 'epoch': 0.96}\n","{'loss': 0.1762, 'learning_rate': 1.1658242295776945e-06, 'epoch': 0.98}\n","{'loss': 0.1919, 'learning_rate': 3.505625305723137e-07, 'epoch': 0.99}\n"]},{"name":"stderr","output_type":"stream","text":["\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n"]},{"name":"stdout","output_type":"stream","text":["{'train_runtime': 9920.2957, 'train_samples_per_second': 0.619, 'train_steps_per_second': 0.619, 'train_loss': 0.2072916038646074, 'epoch': 1.0}\n"]},{"data":{"text/plain":["TrainOutput(global_step=6143, training_loss=0.2072916038646074, metrics={'train_runtime': 9920.2957, 'train_samples_per_second': 0.619, 'train_steps_per_second': 0.619, 'train_loss': 0.2072916038646074, 'epoch': 1.0})"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["Trainer(model=model,  args=training_args, train_dataset=train_dataset, \n","        eval_dataset=val_dataset, data_collator=lambda data: {'input_ids': torch.stack([f[0] for f in data]),\n","                                                              'attention_mask': torch.stack([f[1] for f in data]),\n","                                                              'labels': torch.stack([f[0] for f in data])}).train()"]},{"cell_type":"code","execution_count":41,"metadata":{},"outputs":[],"source":["generated = tokenizer(\"<|startoftext|> The old sailor hit\", return_tensors=\"pt\").input_ids"]},{"cell_type":"code","execution_count":42,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"]}],"source":["sample_outputs = model.generate(generated, do_sample=True, top_k=50, max_length=20, top_p=0.95, temperature=1.5, num_return_sequences=20)"]},{"cell_type":"code","execution_count":43,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["0:  The old sailor hit her in the pocket and put her down on the ground before going off with\n","1:  The old sailor hit her face and watched her back through all the crowd.\n","2:  The old sailor hit his chest and weaved under for the two men to open a ring.\n","3:  The old sailor hit three-dollar a beer when we came in, and Brett paid him and\n","4:  The old sailor hit hard and hard over, putting into my chest, rolling up him toward me\n","5:  The old sailor hit that girl on the chest and then fell limp with exhaustion and took the knife\n","6:  The old sailor hit Brett down hard on the arm for five solid minutes.\n","7:  The old sailor hit Romero and knocked the bull in his pocket into the bull-chest.\n","8:  The old sailor hit and drove a line for a big man as we rode along, not to\n","9:  The old sailor hit him again and said: We say that you love.\n","10:  The old sailor hit me.\n","11:  The old sailor hit for gold, and it paid some money.\n","12:  The old sailor hit him across in his pocket where his name was inscribed on the paperâ€”P\n","13:  The old sailor hit us up.\n","14:  The old sailor hit you with the cigarette.\n","15:  The old sailor hit him as he came up the stairs that night he called it a fiesta\n","16:  The old sailor hit and then hit another bullâ€™s horn.\n","17:  The old sailor hitched a fabled-leg and went in.\n","18:  The old sailor hit his head; the count was on the back from head to foot.\n","19:  The old sailor hit three of the others again.\n"]}],"source":["for i, sample_output in enumerate(sample_outputs):\n","    print(\"{}: {}\".format(i, tokenizer.decode(sample_output, skip_special_tokens=True)))"]},{"cell_type":"code","execution_count":44,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["Configuration saved in /Users/steve/models/hemingway_generation/config.json\n","Model weights saved in /Users/steve/models/hemingway_generation/pytorch_model.bin\n"]}],"source":["model.save_pretrained(\"/Users/steve/models/hemingway_generation\")"]},{"cell_type":"code","execution_count":45,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["tokenizer config file saved in /Users/steve/models/hemingway_generation/tokenizer_config.json\n","Special tokens file saved in /Users/steve/models/hemingway_generation/special_tokens_map.json\n","added tokens file saved in /Users/steve/models/hemingway_generation/added_tokens.json\n"]},{"data":{"text/plain":["('/Users/steve/models/hemingway_generation/tokenizer_config.json',\n"," '/Users/steve/models/hemingway_generation/special_tokens_map.json',\n"," '/Users/steve/models/hemingway_generation/vocab.json',\n"," '/Users/steve/models/hemingway_generation/merges.txt',\n"," '/Users/steve/models/hemingway_generation/added_tokens.json')"]},"execution_count":45,"metadata":{},"output_type":"execute_result"}],"source":["tokenizer.save_pretrained(\"/Users/steve/models/hemingway_generation\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"torch13","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13 (main, Aug 25 2022, 18:24:45) \n[Clang 12.0.0 ]"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"67f030e82dc83e46e375c9862143c2f050702bf26aeee9494179d0591d712143"}}},"nbformat":4,"nbformat_minor":2}
